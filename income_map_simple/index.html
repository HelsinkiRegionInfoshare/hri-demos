<!--
An example of combining aluesarja.fi's PC-Axis data with city area polygons
from geoserver.hel.fi. Combines these to visualize average wages of city areas
on map.

Note that the code at times emphasises (quite heavily) readability on expense
of performance and architecture.
-->

<!--
Include libraries for fetching and combining the datasets.
We use Coffee script as the programming language, jQuery for handling
the Ajax requests and px.js for reading the PC-Axis data, which
requires underscore.js.
-->
<script type="text/javascript" src="../vendor/coffee-script.js"></script>
<script type="text/javascript" src="../vendor/jquery-1.11.0.js"></script>
<script type="text/javascript" src="../vendor/underscore.js"></script>
<script type="text/javascript" src="../vendor/px.js"></script>

<!--
The following block fetches the datasets and combines them. The
visualization is done in a separate block below.
-->
<script type="text/coffeescript">
# Set up some configuration
# URL of the PC-Axis dataset
# A CORS-enabling proxy to the PC-Axis file
STATISTICS_DATA_URL = "http://dev.hel.fi/stats/resources/aluesarjat_a01hkis_vaestotulot/pc_axis"
# Works also with a local file, if eg. the proxy server
# is down.
#STATISTICS_DATA_URL = "A01HKIS_Vaestotulot.px"

# Base url of the geoserver for fetching the area polygons
GEOSERVER_BASE_URL = "http://geoserver.hel.fi/geoserver/"

# Fetch the statistics in PC-Axis format
statistics_promise = $.get(STATISTICS_DATA_URL)

# Fetch the area polygons in GeoJSON format using WFS
wfs_url = GEOSERVER_BASE_URL + "wfs/"
request_parameters = {
    # Specify the dataset to use
    typeName: 'hel:osaalue'
    # Standard WFS request parameters
    srsName: 'EPSG:4326'
    service: 'WFS'
    version: '1.1.0'
    request: 'GetFeature'
    outputFormat: 'application/json'
    }
polygons_promise = $.getJSON(wfs_url, request_parameters)

# Declare a deferred object that will be triggered when the
# data processing is done. Will be used to set up the map visualization
# later on. Declared as a global so it can be accessed from the visualization
# code.
@data_processed_promise = $.Deferred()
# Function for processing the processing the data after the requests are done.
# This is used as a callback for the data requests below.
process_data = (statistics_response, polygons_response) ->
    # The returned data is the first parameter of the responses
    statistics_data = statistics_response[0]
    polygons = polygons_response[0]

    # Create a mapping of area ID's to the polygons. This will be needed to
    # find the statistic of the area later on.
    polygons_by_area = {}
    for polygon in polygons.features
        # Convert the area_id to integer as the datasets differ in these IDs
        # in whether they are zero-padded or not.
        area_id = parseInt(polygon.properties.tunnus)
        polygons_by_area[area_id] = polygon
        # Add array for storing the statistics later on
        polygon.properties.statistics = []
        

    # Use the px.js library for opening the PC-Axis data.
    statistics_px = new Px(statistics_data)
    # Dump some information of the dataset. This can be used to pick
    # the proper columns and values later on.
    console.log("Statistics column names: ", statistics_px.variables())
    console.log("Statistics income classes: ", statistics_px.values('Tuloluokka'))
    console.log("Years available: ", statistics_px.values('Vuosi'))

    # The px.js API allows for faster and more complex handling of the data,
    # but in this example it's just used to convert the table to a list of
    # rows.
    statistics = statistics_px.entries()
    
    # Go through the rows and insert their data in to the matching polygon features.
    # Whether inserting these to the GeoJSON data structure is the best approach
    # depends on the use case, but it enables quite easy map visualization in this
    # example later on.
    for row in statistics
        # The area codes are found embedded in the area name
        # strings in format "<City code> <Area code> <Area name>",
        # so some string processing is needed to extract them. The
        # different hierarchies of the area coding are mixed, but
        # the codes are unique, so this suffices. The data includes also
        # entry for the whole city, which doesn't have the Area code field.
        area_parts = row.Alue.split(" ")
        # The statistics data has zero-padded IDs whereas the WFS data doesn't,
        # so convert to an integer here for compatibility later on.
        area_id = parseInt(area_parts[1])
        
        # px.js returns all entries as strings, so some of these are converted
        # to suitable datatypes.
        row.Vuosi = parseInt(row.Vuosi)
        # The value of the row's statistic ends up in the 'num' column, but
        # is put in to a new attribute to maintain the original values.
        row.value = parseFloat(row.num)

        # Link the data row to the polygon if a matching one is found.
        if area_id not of polygons_by_area
            continue
        polygon = polygons_by_area[area_id]
        polygon.properties.statistics.push row
    
    # Notify that we're done with processing the data
    data_processed_promise.resolve(polygons)
    
# Call the process_data callback after we get the response.
requests_promise = $.when(statistics_promise, polygons_promise)
requests_promise.done(process_data)
# Very rudimentary error handling.
requests_promise.fail( ->
    alert("Fetching data failed. See Javascript console for details.")
    )
</script>


<!--
Set up a very minimal styling and a map element that will hold the
visualization. Declared here so that it will be ready when the code below
runs.
-->
<style type="text/css">
#map {
    width: 100%;
    height: 100%;
    background-color: white;
}

.title {
    position: fixed;
    left: 80px;
    z-index: 100;
    font-size: 12pt;
}
</style>

<h1 class="title">
Helsingin yli 15 vuotiaiden keskitulo alueittain vuonna 2011.
</h1>
<div id="map"></div>

<!--
Include libraries needed for the visualization. Most of the Leaflet map initialization
is done in the separate hel_map.coffee file, which sets up the map to use Helsinki's
official map and its map projection.
-->
<link rel="stylesheet" href="../vendor/leaflet.css" />
<script src="../vendor/leaflet.js"></script>
<script src="../vendor/proj4.js"></script>
<script src="../vendor/proj4leaflet.js"></script>
<script src="../vendor/leaflet-dvf.js"></script>
<script type="text/coffeescript" src="hel_map.coffee"></script>

<script type="text/coffeescript">
# Year of the dataset time series to show
STATISTICS_YEAR = 2011
# The value of interest in the dataset (mean income)
STATISTICS_INCOME_CLASS = 'Keskitulo'

# The visualization is configured in this function, which is used as a callback
# below for when the data processing is done.
setup_map_visualization = (polygons) ->
    
    # Find the rows that we want to show and store them in the area's properties
    # so they will be found quickly later on.
    for polygon in polygons.features
        # Skip polygons with no associated statistics
        if not polygon.properties.statistics
            continue
        for row in polygon.properties.statistics
            # Pick the statistic row of the year and income class
            # specified above.
            if row.Vuosi != STATISTICS_YEAR
                continue
            if row.Tuloluokka != STATISTICS_INCOME_CLASS
                continue
            polygon.properties.statistics_row = row
    
    # Get all values of our statistic of interest to calculate
    # the range.
    all_values = []
    for polygon in polygons.features
        row = polygon.properties.statistics_row
        if not row
            continue
        value = row.value
        # Skip NaNs which indicate that there's no data for the area
        if isNaN(value)
            continue
        all_values.push value
    
    # Create a color mapping for the values. There may be some "outlier" areas with
    # income differing almost order of magnitude the mean, so we'll skip a few
    # of the riches areas in calculating the range maximum. There are better approaches
    # for handling such outliers, but we'll keep it simple here.
    all_values.sort((a, b) -> a - b) # Sort numerically
    min_value = all_values[0]
    max_value = all_values[Math.round(all_values.length*0.95)] # High 5%

    # Creates a green (richest) to red (poorest) colormap
    value_to_color = new L.HSLHueFunction(
            new L.Point(min_value,0),
            new L.Point(max_value,120))

    # Create the Helsinki map to the #map div-element
    map = hel_leaflet_map 'map'
    
    # Create the polygons layer and color them according to the mean income.
    borders_layer = L.geoJson polygons,
        # Skip the polygons that don't have the statistic of interest
        filter: (polygon) ->
            return 'statistics_row' of polygon.properties

        style: (polygon) ->
            # Get the value and force it in to the color mapping range
            value = polygon.properties.statistics_row.value
            if value < min_value
                value = min_value
            if value > max_value
                value = max_value
        
            # Specify the styling and coloring by value
            color = value_to_color.evaluate(value)
            style =
                color: "black"
                fillColor: color
                fillOpacity: 0.8
                weight: 1

            if not value
                style.fillOpacity = 0.1
            return style
         
        # Add a popup for name and value of the area
        onEachFeature: (polygon, layer) ->
            value = polygon.properties.statistics_row.value
            content = "<p>#{polygon.properties.nimi}, keskitulo #{value} euroa</p>"
            layer.bindPopup content

    borders_layer.addTo(map.map)

data_processed_promise.done(setup_map_visualization)
</script>

